{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2W_fF3R7jUc8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2vMg--HjYbf",
        "outputId": "ab722998-bb73-4dd8-adae-aea961a432a1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read and mount data to data frames:\n",
        "\n",
        "path1 = '/content/drive/MyDrive/VU/ANN/prepared_train_data.csv'\n",
        "path2 = '/content/drive/MyDrive/VU/ANN/prepared_test_data.csv'\n",
        "train_df = pd.read_csv(path1)\n",
        "test_df = pd.read_csv(path2)"
      ],
      "metadata": {
        "id": "5w4KH09MjbJt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dimensionality reduction:"
      ],
      "metadata": {
        "id": "b5DioEyhkufL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pop out target data and id column:\n",
        "Y_train = train_df['sales']\n",
        "X_train = train_df.drop('sales', axis=1)\n",
        "X_train = X_train.drop('id', axis=1)\n",
        "\n",
        "# Convert dataframes to tensors\n",
        "X_tensor = torch.tensor(X_train.values[:,:,None], dtype=torch.float32)\n",
        "print(X_tensor.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zWX30gGlVrB",
        "outputId": "5656bb3d-398c-466a-d36a-dc26cc33cb61"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3052566, 88, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Dataset from tensor\n",
        "dataset = TensorDataset(X_tensor, torch.tensor(Y_train.values, dtype=torch.float32))\n",
        "\n",
        "# Defining the DataLoader\n",
        "BATCH_SIZE = 1713  # each store-item has 1713 entries\n",
        "data_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "id": "QAgXHKlqko0C"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_channels, sequence_length, encoded_dim=16):\n",
        "        super(Autoencoder, self).__init__()\n",
        "\n",
        "        # Activation Function\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # Encoder Layers with Batch Normalization\n",
        "        self.fc1_enc = nn.Linear(sequence_length * input_channels, 256)\n",
        "        self.bn1_enc = nn.BatchNorm1d(256)\n",
        "        self.fc2_enc = nn.Linear(256, 128)\n",
        "        self.bn2_enc = nn.BatchNorm1d(128)\n",
        "        self.fc3_enc = nn.Linear(128, 64)\n",
        "        self.bn3_enc = nn.BatchNorm1d(64)\n",
        "        self.fc4_enc = nn.Linear(64, encoded_dim)\n",
        "\n",
        "        # Decoder Layers with Batch Normalization\n",
        "        self.fc1_dec = nn.Linear(encoded_dim, 64)\n",
        "        self.bn1_dec = nn.BatchNorm1d(64)\n",
        "        self.fc2_dec = nn.Linear(64, 128)\n",
        "        self.bn2_dec = nn.BatchNorm1d(128)\n",
        "        self.fc3_dec = nn.Linear(128, 256)\n",
        "        self.bn3_dec = nn.BatchNorm1d(256)\n",
        "        self.fc4_dec = nn.Linear(256, sequence_length * input_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoding\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
        "        x = self.relu(self.bn1_enc(self.fc1_enc(x)))\n",
        "        x = self.relu(self.bn2_enc(self.fc2_enc(x)))\n",
        "        x = self.relu(self.bn3_enc(self.fc3_enc(x)))\n",
        "        encoded = self.fc4_enc(x)\n",
        "\n",
        "        # Decoding\n",
        "        x = self.relu(self.bn1_dec(self.fc1_dec(encoded)))\n",
        "        x = self.relu(self.bn2_dec(self.fc2_dec(x)))\n",
        "        x = self.relu(self.bn3_dec(self.fc3_dec(x)))\n",
        "        decoded = self.fc4_dec(x)\n",
        "\n",
        "        return decoded\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu(self.bn1_enc(self.fc1_enc(x)))\n",
        "        x = self.relu(self.bn2_enc(self.fc2_enc(x)))\n",
        "        x = self.relu(self.bn3_enc(self.fc3_enc(x)))\n",
        "        encoded = self.fc4_enc(x)\n",
        "        return encoded\n"
      ],
      "metadata": {
        "id": "rsEoGxesk6JG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0. Use GPU if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 1. Model Initialization\n",
        "input_channels = X_tensor.shape[1]       # 88\n",
        "sequence_length = X_tensor.shape[2]      # 1\n",
        "model = Autoencoder(input_channels, sequence_length).to(device)  # Move model to GPU if available"
      ],
      "metadata": {
        "id": "jrwQNXWr1Mtt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Train encoder:\n",
        "\n",
        "# 2. Loss Function\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# 3. Optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "\n",
        "# 4. Training Loop\n",
        "num_epochs = 8\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for batch_idx, (data, target) in enumerate(data_loader):\n",
        "        data = data.to(device)\n",
        "\n",
        "        optimizer.zero_grad()  # Reset gradients\n",
        "        reconstructed = model(data)\n",
        "        loss = criterion(reconstructed, data.view(data.size(0), -1))        # -1 - infer the size for that particular dimension based on the original size and the size of the other specified dimensions\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] Loss: {running_loss/len(data_loader):.4f}\")\n",
        "\n",
        "# 6. Model Saving (optional)\n",
        "torch.save(model.state_dict(), 'model_weights.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2B-wL2AqlANk",
        "outputId": "ce634212-c42c-4bee-e573-ee077850de69"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/8] Loss: 0.0220\n",
            "Epoch [2/8] Loss: 0.0118\n",
            "Epoch [3/8] Loss: 0.0099\n",
            "Epoch [4/8] Loss: 0.0074\n",
            "Epoch [5/8] Loss: 0.0042\n",
            "Epoch [6/8] Loss: 0.0028\n",
            "Epoch [7/8] Loss: 0.0024\n",
            "Epoch [8/8] Loss: 0.0022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encode training data:"
      ],
      "metadata": {
        "id": "leHepvUqVHsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved weights\n",
        "model.load_state_dict(torch.load('model_weights.pth'))\n",
        "model.eval()  # Set the model to evaluation mode by ignoring drop outs & batch normalization\n",
        "\n",
        "encoded_data = []\n",
        "with torch.no_grad():\n",
        "    for data, _ in data_loader:  # no need of targets for encoding\n",
        "        data = data.to(device)\n",
        "        encoded = model.encode(data)\n",
        "        encoded_data.append(encoded.cpu())\n",
        "\n",
        "# Convert list of tensors to a single tensor\n",
        "encoded_data = torch.cat(encoded_data, dim=0)\n",
        "\n",
        "print(encoded_data.shape)"
      ],
      "metadata": {
        "id": "S5_O27CjrkSm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b54275c8-54c1-436c-efdb-ab15b460eb29"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3052566, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encode test data:"
      ],
      "metadata": {
        "id": "T-Xw-widVNvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_data.shape"
      ],
      "metadata": {
        "id": "qrucFm2uA88h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "913f6539-af27-4ae2-ff46-e34ea6534ccb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3052566, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Storing encoded data:"
      ],
      "metadata": {
        "id": "GN4TXfPRq5zt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert list of tensors to numpy array\n",
        "encoded_data_array = np.vstack([tensor.numpy() for tensor in encoded_data])\n",
        "\n",
        "# Convert numpy array to DataFrame\n",
        "encoded_df = pd.DataFrame(encoded_data_array)\n",
        "# Concatenate encoded_df and Y_train along columns\n",
        "encoded_df_plus_sales = pd.concat([encoded_df, train_df['id'].reset_index(drop=True), Y_train.reset_index(drop=True)], axis=1)\n",
        "\n",
        "# Save to CSV\n",
        "encoded_df_plus_sales.to_csv('/content/drive/MyDrive/VU/ANN/encoded_data.csv', index=False)"
      ],
      "metadata": {
        "id": "4bW88Ilkq-R4"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}